const { OutputAdapter } = require('./outputAdapter');

const SHARED_DB_META_DATA = {
  DB_NAME: 'trustdble',
  TABLE_NAME: 'shared_databases',
  DATABASES_NAME_COL: 'database_name',
  BLOCKCHAIN_TYPE_COL: 'blockchain_type',
  DB_STATE_COL: 'database_state',
};

const BLOCKCHAIN_TYPES = {
  ETHEREUM: 'ETHEREUM',
};

const SHARED_TABLE_META_DATA = {
  TABLE_NAME: 'shared_tables',
  TABLES_NAME_COL: 'partition_id',
  CONTRACT_ADDRESS_COL: 'tableaddress',
  TABLE_SCHEMA_COL: 'tableschema',
};

const KEY_STORE_META_DATA = {
  TABLE_NAME: 'key_store',
  TABLES_NAME_COL: 'tablename',
  ENCRYPTION_KEY_COL: 'encryptionkey',
  INITIAL_VECTOR_COL: 'iv',
};

const DATA_CHAIN_META_DATA = {
  TABLE_NAME: 'data_chains',
  ID_COL: 'datachain_id',
  DATA_CHAIN_CONFIG_COL: 'connection_information',
};

const HISTORY_TABLES = {
  TABLE_NAME_PREFIX: 'history_',
  BLOCK_NUMBER_COL: 'blockNumber',
};

const DEFAULT_COLUMNS = {
  AS_OF_COLUMN: 'datetime',
  DATA_CHAIN_ID_COLUMN: 'dataChainId',
  BLOCK_NUMBER_COLUMN: 'blockNumber',
  TRANSACTION_ID: 'transactionId',
  TRANSACTION_TYPE: 'transactionType',
  EDITOR_COLUMN: 'editor',
  KEY_COLUMN: 'primaryKeyHash',
  VALUE_COLUMN: 'dataValue',
};

/**
 * Adapter for persisting the blockchain history into a SQL database.
 * The adapter only requires the given database to exist but will create all necessary tables.
 *
 * The tables generated by this adapter and the data within it are consumed by the Backend API.
 * We required only database connection
 *
 * Before tuples can be written you should make sure
 * that tables are initialized using the initHistoryTables method.
 */
class SQLAdapter extends OutputAdapter {
  constructor(dbConnection) {
    super();
    this.dbConnection = dbConnection;
  }

  /**
     * Ensures that all necessary tables exist and creates them if not.
     * Should be called before your first writeTuple call.
     *
     * @param {string} dbName Name of database in which the table should be created
     * @param {Object} tableNameList List of table names to be created
     * @returns {Promise<void>} Promise that resolves once all tables are ensured to exist.
     */
  async initHistoryTables(dbName, tableNameList) {
    tableNameList.forEach(async (tableName) => {
      // Check if necessary tables exists and create if not
      await this._createTable(dbName, HISTORY_TABLES.TABLE_NAME_PREFIX + tableName);
    });
  }

  /**
     * Creates the table dbName.tableName
     *
     * @param {string} dbName Name of database in which the table should be created
     * @param {string} tableName Name of table to be created
     * @returns {Promise<*>} Resolves when the table is created
     * @private
     */
  async _createTable(dbName, tableName) {
    const query = `CREATE TABLE IF NOT EXISTS ${dbName}.${tableName} (${DEFAULT_COLUMNS.AS_OF_COLUMN} TIMESTAMP, `
            + `${DEFAULT_COLUMNS.DATA_CHAIN_ID_COLUMN} INT, ${DEFAULT_COLUMNS.BLOCK_NUMBER_COLUMN} INT, `
            + `${DEFAULT_COLUMNS.EDITOR_COLUMN} VARCHAR(128), ${DEFAULT_COLUMNS.TRANSACTION_ID} VARCHAR(128) UNIQUE, `
            + `${DEFAULT_COLUMNS.TRANSACTION_TYPE} VARCHAR(16), `
            + `${DEFAULT_COLUMNS.KEY_COLUMN} VARCHAR(128), ${DEFAULT_COLUMNS.VALUE_COLUMN} TEXT);`;
    return this.dbConnection.query(query);
  }

  /**
     * Construct the query used for inserting a single tuple into the history table.
     *
     * @param {string} dbName Name of database in which the table should be created
     * @param {string} tableName Name of table to be created
     * @returns {string} Query ready to be executed.
     * @private
     */
  static _constructTupleQuery(dbName, tableName) {
    return `INSERT INTO ${dbName}.${HISTORY_TABLES.TABLE_NAME_PREFIX}${tableName}(${DEFAULT_COLUMNS.AS_OF_COLUMN}, `
                + `${DEFAULT_COLUMNS.DATA_CHAIN_ID_COLUMN}, `
                + `${DEFAULT_COLUMNS.BLOCK_NUMBER_COLUMN}, ${DEFAULT_COLUMNS.EDITOR_COLUMN}, ${DEFAULT_COLUMNS.TRANSACTION_ID}, `
                + `${DEFAULT_COLUMNS.TRANSACTION_TYPE}, ${DEFAULT_COLUMNS.KEY_COLUMN}, `
                + `${DEFAULT_COLUMNS.VALUE_COLUMN}) VALUES (?, ?, ?, ? ,?, ?, ?, ?);`;
  }

  /**
     * Takes a tuple and writes it into the corresponding table.
     *
     * Expects the tuple to have the following structure:
     * {
     *     asOf: datetime,
     *     blockNumber: int,
     *     editor: string,
     *     transactionID: string,
     *     key: string,
     *     value: string
     * }
     *
     * @param {string} dbName Name of database in which the table should be created
     * @param {string} tableName Name of table to be created
     * @param {object} tuple Tuple (i.e. one write to the blockchain) to be persisted
     * @returns {Promise<*>} Promise that resolves once the tuple has been written to the DB.
     */
  async writeTuple(dbName, tableName, dataChainId, tuple) {
    const queryValues = [
      tuple.asOf,
      dataChainId,
      tuple.blockNumber,
      tuple.editor,
      tuple.txHash,
      tuple.txType,
      tuple.keyHash,
      tuple.value,
    ];
    return this.dbConnection.query(
      this.constructor._constructTupleQuery(dbName, tableName),
      queryValues,
    );
  }

  /**
     * To get databases names
     * Which can be found from 'shared_databases' table of 'trustdble' database
     *
     * @returns {[list]} list of shared databases
     */
  async getSharedDatabases() {
    try {
      const results = await this.dbConnection.query(`SELECT ${SHARED_DB_META_DATA.DATABASES_NAME_COL} `
                                + `FROM ${SHARED_DB_META_DATA.DB_NAME}.${SHARED_DB_META_DATA.TABLE_NAME} `
                                + `WHERE ${SHARED_DB_META_DATA.BLOCKCHAIN_TYPE_COL}='${BLOCKCHAIN_TYPES.ETHEREUM}' `
                                + `AND ${SHARED_DB_META_DATA.DB_STATE_COL}='CREATED'`);

      return results.map((element) => element[SHARED_DB_META_DATA.DATABASES_NAME_COL]);
    } catch (err) {
      console.error(err);
      return [];
    }
  }

  /**
     * To get List of shared tables and their contract addresses and schemas
     * Which can be found from the 'meta_table' of each shared database
     *
     * @param {string} dbName Name of shared database
     * @returns {[object, object]} List of tableNamesDict and tableSchemasDict
     */
  async getSharedTables(dbName) {
    const tableNamesDict = {};
    const tableSchemasDict = {};
    const keysAndSchemaDict = {};
    try {
      const sharedTable = await this.dbConnection
        .query(`USE ${dbName}; `
            + `SELECT * FROM ${SHARED_TABLE_META_DATA.TABLE_NAME} `
            + `WHERE ${SHARED_TABLE_META_DATA.TABLE_SCHEMA_COL}<>''`);
      // Map tables name over contract addresses as key value relation
      // Map tables schema over contract addresses as key value relation
      // Add contract address as key and table name and schema as value
      sharedTable[1].forEach((table) => {
        const tableName = table[SHARED_TABLE_META_DATA.TABLES_NAME_COL].split('/')[0];
        const dataChainId = table[SHARED_TABLE_META_DATA.TABLES_NAME_COL].split('/')[1];
        const contractAddress = table[SHARED_TABLE_META_DATA.CONTRACT_ADDRESS_COL];

        // Contract addresses can be same in different data chains for different tables
        // So we need to to separate them by data chain id
        if (dataChainId in tableNamesDict) {
          tableNamesDict[dataChainId][contractAddress] = tableName;
        } else {
          tableNamesDict[dataChainId] = {};
          tableNamesDict[dataChainId][contractAddress] = tableName;
        }

        /**
         * Table schema received like "id INT, name varchar (20), gender CHAR (2)"
         * But we need only column types so first we split them and filter to get only types
         * We are parsing a table schema received from meta_table which comes with all information
         * like column name, type, have key (primary, foreign), and is null
         * But, we only need to fetch column types for decoding.
         *
         * For example, we have table Schema:
         *
         * "`wasteId` INT AUTO_INCREMENT,
         * `date` DATE,
         * `consignmentBill` BLOB,
         * `transportationType` ENUM('Merck', 'Pick-up', 'FET') NOT NULL,
         * `formOfDelivery` VARCHAR (50),
         * `pickUpAddress` INT NOT NULL,
         * PRIMARY KEY (`wasteId`),
         * FOREIGN KEY (`pickUpAddress`) REFERENCES `Addresses`(`addressId`)"
         *
         * Parsing steps:
         * 1. We convert schema in lowercase because in decoding,
         *    we are dealing with only lowercase types
         * 2. We need to separate each column information name, type, key, or null
         * 3. Each column can contain some spaces, alphabets in both upper or lower,
         *    some digits, and special characters _ ` ( ) using match() we can separate them.
         * 4. If you see in example data type of a column comes at 2nd position.
         * 5. Type can also have alphabets, digits and parentheses ( )
         *    which can be fetch using match()
         * 6. Last two columns have extra information regarding 'KEY'
         *    which is not required for decoding so, we filter them.
         */
        tableSchemasDict[
          table[
            SHARED_TABLE_META_DATA.TABLES_NAME_COL
          ].split('/')[0]
        ] = table[SHARED_TABLE_META_DATA.TABLE_SCHEMA_COL].toLowerCase()
          .match(/[A-Za-z0-9_` ]+(\([^)]+\))?([A-Za-z0-9_` ]+(\([^)]+\))?)?/g)
          .map((el) => el.trim().replace(' (', '(').match(/\w+(\([^)]+\))?/g)[1])
          .filter((type) => !type.startsWith('key'));
      });

      const keyStore = await this.dbConnection
        .query(`USE ${dbName}; `
            + `SELECT * FROM ${KEY_STORE_META_DATA.TABLE_NAME}`);

      // Map tables schema, encryptionKey, iv over tables name as key value relation
      keyStore[1].forEach((table) => {
        keysAndSchemaDict[
          table[
            KEY_STORE_META_DATA.TABLES_NAME_COL
          ]
        ] = {
          tableSchema: tableSchemasDict[table[KEY_STORE_META_DATA.TABLES_NAME_COL]],
          encryptionKey: table[KEY_STORE_META_DATA.ENCRYPTION_KEY_COL],
          iv: table[KEY_STORE_META_DATA.INITIAL_VECTOR_COL],
        };
      });
    } catch (err) {
      console.error(err);
    }
    return {
      tableNamesDict, keysAndSchemaDict,
    };
  }

  /**
   * To list of network URLs to read data from multiple data chains
   * Network URLs can be fetch from 'data_chains' table
   *
   * @param {string} dbName Name of shared database
   * @returns {[string]} List of networkURLs
   */
  async getNetworkURLs(dbName) {
    try {
      const results = await this.dbConnection.query(`USE ${dbName}; SELECT * `
                                + `FROM ${DATA_CHAIN_META_DATA.TABLE_NAME} `
                                + `ORDER BY ${DATA_CHAIN_META_DATA.ID_COL}`);

      const networkURLs = [];

      results[1].forEach((element) => {
        const obj = JSON.parse(element[DATA_CHAIN_META_DATA.DATA_CHAIN_CONFIG_COL]);
        networkURLs.push({
          dataChainId: element[DATA_CHAIN_META_DATA.ID_COL],
          networkURL: `http://127.0.0.1:${obj.Network['rpc-port']}`,
        });
      });
      return networkURLs;
    } catch (err) {
      console.error(err);
      return [];
    }
  }

  /**
     * To get List of history tables if exists
     *
     * @param {string} dbName Name of shared database
     * @returns {[string]} List of history table names
     */
  async _getHistoryTables(dbName) {
    try {
      const historyTablesList = [];
      const results = await this.dbConnection.query(`USE ${dbName}; SHOW TABLES LIKE '${HISTORY_TABLES.TABLE_NAME_PREFIX}%'`);
      results[1].forEach((element) => {
        historyTablesList.push(element[`Tables_in_${dbName} (${HISTORY_TABLES.TABLE_NAME_PREFIX}%)`]);
      });
      return historyTablesList;
    } catch (err) {
      console.error(err);
      return [];
    }
  }

  /**
     * To get a highest processed block number from history tables of a database
     *
     * @param {string} dbName Name of shared database
     * @returns {int} Highest block number / Last processed block number
     */
  async getLastProcessedBlockNr(dbName, dataChainId) {
    try {
      let lastBlockNr = -1;
      for (const historyTableName of await this._getHistoryTables(dbName)) {
        let tableMaxBlockNr;
        await this.dbConnection.query(`SELECT MAX(${HISTORY_TABLES.BLOCK_NUMBER_COL}) `
                        + `AS ${HISTORY_TABLES.BLOCK_NUMBER_COL} FROM ${dbName}.${historyTableName} `
                        + `WHERE ${DEFAULT_COLUMNS.DATA_CHAIN_ID_COLUMN}=${dataChainId}`).then((res) => {
          tableMaxBlockNr = res[0][HISTORY_TABLES.BLOCK_NUMBER_COL];
        });
        lastBlockNr = (tableMaxBlockNr !== null && tableMaxBlockNr > lastBlockNr)
          ? tableMaxBlockNr
          : lastBlockNr;
      }
      return lastBlockNr;
    } catch (err) {
      console.error(err);
      return undefined;
    }
  }
}

module.exports = { SQLAdapter };
